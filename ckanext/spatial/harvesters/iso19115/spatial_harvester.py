import re
import six
from six.moves.urllib.parse import urlparse, urlunparse, urlencode

from lxml import etree

from ckan import logic
from ckan import model
from ckan import plugins as p
from ckantoolkit import config

from ckan.lib.navl.validators import not_empty
from ckan.plugins.core import SingletonPlugin, implements

from ckanext.spatial.harvesters.base import SpatialHarvester
from ckanext.spatial.interfaces import ISpatialHarvester

# IHarvester
from ckanext.spatial.harvesters.csw import CSWHarvester
from ckanext.spatial.harvesters.iso19115.model import ISO19115Document
from ckanext.harvest.interfaces import IHarvester
from ckanext.harvest.model import HarvestObject

import logging
log = logging.getLogger(__name__)

class ISO19115SpatialHarvester(SpatialHarvester, SingletonPlugin):
    csw_harvester = None

    def _get_csw_harvester(self):
        if not self.csw_harvester:
            try:
                self.csw_harvester = p.get_plugin('csw_harvester')
            except Exception as e:
                log.error('Failed to get package from base implementation:\n%r', str(e))
                raise e

        return self.csw_harvester

    '''
    An harvester for ISO19115 metadata
    '''
    implements(ISpatialHarvester)

    # ISpatialHarvester

    # From parent SpatialHarvester
    def get_package_dict(self, context, data_dict):
        '''
        Allows to modify the dataset dict that will be created or updated

        This is the dict that the harvesters will pass to the `package_create`
        or `package_update` actions. Extensions can modify it to suit their
        needs, adding or removing filds, modifying the default ones, etc.

        This method should always return a package_dict. Note that, although
        unlikely in a particular instance, this method could be implemented by
        more than one plugin.

        If a dict is not returned by this function, the import stage will be
        cancelled.


        :param context: Contains a reference to the model, eg to
                        perform DB queries, and the user name used for
                        authorization.
        :type context: dict
        :param data_dict: Available data. Contains four keys:

            * `package_dict`
               The default package_dict generated by the harvester. Modify this
               or create a brand new one.
            * `iso_values`
               The parsed ISO XML document values. These contain more fields
               that are not added by default to the ``package_dict``.
            * `xml_tree`
               The full XML etree object. If some values not present in
               ``iso_values`` are needed, these can be extracted via xpath.
            * `harvest_object`
               A ``HarvestObject`` domain object which contains a reference
               to the original metadata document (``harvest_object.content``)
               and the harvest source (``harvest_object.source``).

        :type data_dict: dict

        :returns: A dataset dict ready to be used by ``package_create`` or
                  ``package_update``
        :rtype: dict
        '''
        _dict = data_dict['package_dict']
        _values = data_dict['iso_values']
        # _tree = data_dict['xml_tree']
        _object = data_dict['harvest_object']
        # _dict2 = elem2dict(_tree)

        # TODO readme (below)
        return self._fault_tolerant_get_package_dict(_values, _object)


    def get_validators(self):
        '''
        Allows to register custom Validators that can be applied to harvested
        metadata documents.

        Validators are classes that implement the ``is_valid`` method. Check
        the `Writing custom validators`_ section in the docs to know more
        about writing custom validators.

        :returns: A list of Validator classes
        :rtype: list
        '''
        import ckanext.spatial.harvesters.iso19115.validators as validators
        return [
                  validators.ISO19115_Schema,
                  validators.ISO19115_2_Schema,
                  validators.ISO19115_1_Schema,
                  validators.ISO19115_Schematron]

    # From parent SpatialHarvester
    # def transform_to_iso(self, original_document, original_format, harvest_object):
        # '''
        # Transforms an XML document to ISO 19139

        # This method will be only called from the import stage if the
        # harvest_object content is null and original_document and
        # original_format harvest object extras exist (eg if an FGDC document
        # was harvested).

        # In that case, this method should do the necessary to provide an
        # ISO 1939 like document, otherwise the import process will stop.


        # :param original_document: Original XML document
        # :type original_document: string
        # :param original_format: Original format (eg 'fgdc')
        # :type original_format: string
        # :param harvest_object: HarvestObject domain object (with access to
        #     job and source objects)
        # :type harvest_object: HarvestObject

        # :returns: An ISO 19139 document or None if the transformation was not
        #     successful
        # :rtype: string

        # '''
        # return None


### TODO provide PR to master and remove

    # TODO removeme
    # We are extending concrete class SpatialHarvester 
    # to delegate some of the self.... methods below
    # this imply beeing a IHarvester as well....
    # Once removed below functions no need to extend anymore
    # we can be a pure ISpatialHarvester
    def info(self):
        return {
            'name': 'iso19115_harvester',
            'title': 'new ISO19115 CSW based',
            'description': ''
            }

    # source_config = {}

    # force_import = False

    # delegate
    # TODO waiting for pull request merge
    def _guess_resource_format(self, resource_locator, use_mimetypes=True):
        import ckanext.spatial.harvesters.base as b
        return b.guess_resource_format(resource_locator, use_mimetypes=True)

    def _fault_tolerant_get_package_dict(self, iso_values, harvest_object):
        '''
        DEPRECATED: should be used untill PR on master are accepted

        Constructs a package_dict suitable to be passed to package_create or
        package_update. See documentation on
        ckan.logic.action.create.package_create for more details

        '''

        from string import Template
        from datetime import datetime
        from six.moves.urllib.parse import urlparse
        # from owslib import wms
        # from lxml import etree
        from ckanext.harvest.harvesters.base import munge_tag
        from ckan.lib.helpers import json
        tags = []

        if 'tags' in iso_values:
            do_clean = self.source_config.get('clean_tags')
            tags_val = [munge_tag(tag) if do_clean else tag[:100] for tag in iso_values['tags']]
            tags = [{'name': tag} for tag in tags_val]

        # Add default_tags from config
        default_tags = self.source_config.get('default_tags', [])
        if default_tags:
            for tag in default_tags:
                tags.append({'name': tag})

        package_dict = {
            'title': iso_values['title'],
            'notes': iso_values['abstract'],
            'tags': tags,
            'resources': [],
        }

        # We need to get the owner organization (if any) from the harvest
        # source dataset
        source_dataset = model.Package.get(harvest_object.source.id)
        if source_dataset.owner_org:
            package_dict['owner_org'] = source_dataset.owner_org

        # Package name
        package = harvest_object.package
        if package is None or package.title != iso_values['title']:
            name = self._gen_new_name(iso_values['title'])
            if not name:
                name = self._gen_new_name(six.text_type(iso_values['guid']))
            if not name:
                raise Exception('Could not generate a unique name from the title or the GUID. Please choose a more unique title.')
            package_dict['name'] = name
        else:
            package_dict['name'] = package.name

        extras = {
            'guid': harvest_object.guid,
            'spatial_harvester': True,
        }

        # Just add some of the metadata as extras, not the whole lot
        for name in [
            # Essentials
            'spatial-reference-system',
            'guid',
            # Usefuls
            'dataset-reference-date',
            'metadata-language',  # Language
            'metadata-date',  # Released
            'coupled-resource',
            'contact-email',
            'frequency-of-update',
            'spatial-data-service-type',
        ]:
            extras[name] = iso_values[name]

        if len(iso_values.get('progress', [])):
            extras['progress'] = iso_values['progress'][0]
        else:
            extras['progress'] = ''

        if len(iso_values.get('resource-type', [])):
            extras['resource-type'] = iso_values['resource-type'][0]
        else:
            extras['resource-type'] = ''

        extras['licence'] = iso_values.get('use-constraints', '')

        def _extract_first_license_url(licences):
            for licence in licences:
                o = urlparse(licence)
                if o.scheme and o.netloc:
                    return licence
            return None

        if len(extras['licence']):
            license_url_extracted = _extract_first_license_url(extras['licence'])
            if license_url_extracted:
                extras['licence_url'] = license_url_extracted


        # Metadata license ID check for package
        use_constraints = iso_values.get('use-constraints')
        if use_constraints:

            context = {'model': model, 'session': model.Session, 'user': self._get_user_name()}
            license_list = p.toolkit.get_action('license_list')(context, {})

            for constraint in use_constraints:
                package_license = None

                for license in license_list:
                    if constraint.lower() == license.get('id') or constraint == license.get('url'):
                        package_license = license.get('id')
                        break

                if package_license:
                    package_dict['license_id'] = package_license
                    break


        extras['access_constraints'] = iso_values.get('limitations-on-public-access', '')

        # Grpahic preview
        browse_graphic = iso_values.get('browse-graphic')
        if browse_graphic:
            browse_graphic = browse_graphic[0]
            extras['graphic-preview-file'] = browse_graphic.get('file')
            if browse_graphic.get('description'):
                extras['graphic-preview-description'] = browse_graphic.get('description')
            if browse_graphic.get('type'):
                extras['graphic-preview-type'] = browse_graphic.get('type')


        for key in ['temporal-extent-begin', 'temporal-extent-end']:
            if len(iso_values.get(key, '')) > 0:
                extras[key] = iso_values[key][0]

        # Save responsible organization roles
        if iso_values['responsible-organisation']:
            parties = {}
            for party in iso_values['responsible-organisation']:
                if party['organisation-name'] in parties:
                    if not party['role'] in parties[party['organisation-name']]:
                        parties[party['organisation-name']].append(party['role'])
                else:
                    parties[party['organisation-name']] = [party['role']]
            extras['responsible-party'] = [{'name': k, 'roles': v} for k, v in parties.items()]

        if len(iso_values.get('bbox',[])) > 0:
            bbox = iso_values['bbox'][0]
            extras['bbox-east-long'] = bbox['east']
            extras['bbox-north-lat'] = bbox['north']
            extras['bbox-south-lat'] = bbox['south']
            extras['bbox-west-long'] = bbox['west']

            if iso_values.get('spatial'):
                extras['spatial'] = iso_values['spatial']
            else:
                try:
                    xmin = float(bbox['west'])
                    xmax = float(bbox['east'])
                    ymin = float(bbox['south'])
                    ymax = float(bbox['north'])
                except ValueError as e:
                    self._save_object_error('Error parsing bounding box value: {0}'.format(six.text_type(e)),
                                        harvest_object, 'Import')
                else:
                    # Construct a GeoJSON extent so ckanext-spatial can register the extent geometry

                    # Some publishers define the same two corners for the bbox (ie a point),
                    # that causes problems in the search if stored as polygon
                    if xmin == xmax or ymin == ymax:
                        extent_string = Template('{"type": "Point", "coordinates": [$x, $y]}').substitute(
                            x=xmin, y=ymin
                        )
                        self._save_object_error('Point extent defined instead of polygon',
                                        harvest_object, 'Import')
                    else:
                        extent_string = self.extent_template.substitute(
                            xmin=xmin, ymin=ymin, xmax=xmax, ymax=ymax
                        )
                    extras['spatial'] = extent_string.strip()
        else:
            log.debug('No spatial extent defined for this object')

        resource_locators = iso_values.get('resource-locator', []) +\
            iso_values.get('resource-locator-identification', [])

        if len(resource_locators):
            for resource_locator in resource_locators:
                url = resource_locator.get('url', '').strip()
                if url:
                    resource = {}
                    resource['format'] = self._guess_resource_format(resource_locator)
                    if resource['format'] == 'wms' and config.get('ckanext.spatial.harvest.validate_wms', False):
                        # Check if the service is a view service
                        test_url = url.split('?')[0] if '?' in url else url
                        if self._is_wms(test_url):
                            resource['verified'] = True
                            resource['verified_date'] = datetime.now().isoformat()

                    resource.update(
                        {
                            'url': url,
                            'name': resource_locator.get('name') or p.toolkit._('Unnamed resource'),
                            'description': resource_locator.get('description') or  '',
                            'resource_locator_protocol': resource_locator.get('protocol') or '',
                            'resource_locator_function': resource_locator.get('function') or '',
                        })
                    package_dict['resources'].append(resource)

        extras['lineage'] = iso_values.get('lineage')

        # Add default_extras from config
        default_extras = self.source_config.get('default_extras',{})
        if default_extras:
           override_extras = self.source_config.get('override_extras',False)
           for key,value in default_extras.items():
              log.debug('Processing extra %s', key)
              if not key in extras or override_extras:
                 # Look for replacement strings
                 if isinstance(value,six.string_types):
                    value = value.format(harvest_source_id=harvest_object.job.source.id,
                             harvest_source_url=harvest_object.job.source.url.strip('/'),
                             harvest_source_title=harvest_object.job.source.title,
                             harvest_job_id=harvest_object.job.id,
                             harvest_object_id=harvest_object.id)
                 extras[key] = value

        extras_as_dict = []
        for key, value in extras.items():
            if isinstance(value, (list, dict)):
                extras_as_dict.append({'key': key, 'value': json.dumps(value)})
            else:
                extras_as_dict.append({'key': key, 'value': value})

        package_dict['extras'] = extras_as_dict

        return package_dict

#################################################################

# IHarvester

    implements(IHarvester)

    # CSWHarvester
    # From parent SpatialHarvester
    # def validate_config(self, config):
        # '''

        # [optional]

        # Harvesters can provide this method to validate the configuration
        # entered in the form. It should return a single string, which will be
        # stored in the database.  Exceptions raised will be shown in the form's
        # error messages.

        # :param harvest_object_id: Config string coming from the form
        # :returns: A string with the validated configuration options
        # '''
        # # Delegate
        # return self._csw.validate_config(config)

    # Delegate to CSWHarvester
    def get_original_url(self, harvest_object_id):
        '''
        [optional]

        This optional but very recommended method allows harvesters to return
        the URL to the original remote document, given a Harvest Object id.
        Note that getting the harvest object you have access to its guid as
        well as the object source, which has the URL.
        This URL will be used on error reports to help publishers link to the
        original document that has the errors. If this method is not provided
        or no URL is returned, only a link to the local copy of the remote
        document will be shown.

        Examples:
            * For a CKAN record: http://{ckan-instance}/api/rest/{guid}
            * For a WAF record: http://{waf-root}/{file-name}
            * For a CSW record: http://{csw-server}/?Request=GetElementById&Id={guid}&...

        :param harvest_object_id: HarvestObject id
        :returns: A string with the URL to the original document
        '''
        # # Delegate
        return self._get_csw_harvester().gather_stage(harvest_object_id)

    # NOT overriding waiting for merge #258
    # delegate to CSWHarvester
    def gather_stage(self, harvest_job):
        # '''
        # The gather stage will receive a HarvestJob object and will be
        # responsible for:
        #     - gathering all the necessary objects to fetch on a later.
        #       stage (e.g. for a CSW server, perform a GetRecords request)
        #     - creating the necessary HarvestObjects in the database, specifying
        #       the guid and a reference to its job. The HarvestObjects need a
        #       reference date with the last modified date for the resource, this
        #       may need to be set in a different stage depending on the type of
        #       source.
        #     - creating and storing any suitable HarvestGatherErrors that may
        #       occur.
        #     - returning a list with all the ids of the created HarvestObjects.
        #     - to abort the harvest, create a HarvestGatherError and raise an
        #       exception. Any created HarvestObjects will be deleted.

        # :param harvest_job: HarvestJob object
        # :returns: A list of HarvestObject ids
        # '''

        # #TODO ########################################################################
        # # be sure to reload config
        # self._set_source_config(harvest_job.source.config)
        # #########################################################################

        return self._get_csw_harvester().gather_stage(harvest_job)
        
    # NOT overriding waiting for merge #258
    # Delegating to CSWHarvester
    def fetch_stage(self,harvest_object):
        '''
        The fetch stage will receive a HarvestObject object and will be
        responsible for:
            - getting the contents of the remote object (e.g. for a CSW server,
            perform a GetRecordById request).
            - saving the content in the provided HarvestObject.
            - creating and storing any suitable HarvestObjectErrors that may
            occur.
            - returning True if everything is ok (ie the object should now be
            imported), "unchanged" if the object didn't need harvesting after
            all (ie no error, but don't continue to import stage) or False if
            there were errors.

        :param harvest_object: HarvestObject object
        :returns: True if successful, 'unchanged' if nothing to import after
                all, False if not successful
        '''
        return self._get_csw_harvester().fetch_stage(harvest_object)

    # From parent SpatialHarvester
    def import_stage(self, harvest_object):
        '''
        The import stage will receive a HarvestObject object and will be
        responsible for:
            - performing any necessary action with the fetched object (e.g.
              create, update or delete a CKAN package).
              Note: if this stage creates or updates a package, a reference
              to the package should be added to the HarvestObject.
            - setting the HarvestObject.package (if there is one)
            - setting the HarvestObject.current for this harvest:
               - True if successfully created/updated
               - False if successfully deleted
            - setting HarvestObject.current to False for previous harvest
              objects of this harvest source if the action was successful.
            - creating and storing any suitable HarvestObjectErrors that may
              occur.
            - creating the HarvestObject - Package relation (if necessary)
            - returning True if the action was done, "unchanged" if the object
              didn't need harvesting after all or False if there were errors.

        NB You can run this stage repeatedly using 'paster harvest import'.

        :param harvest_object: HarvestObject object
        :returns: True if the action was done, "unchanged" if the object didn't
                  need harvesting after all or False if there were errors.
        '''

        log = logging.getLogger(__name__ + '.import')
        log.debug('Import stage for harvest object: %s', harvest_object.id)

        # check arguments
        if not harvest_object:
            log.error('No harvest object received')
            return False
        elif harvest_object.content is None:
            self._save_object_error('Empty content for object {0}'.format(harvest_object.id), harvest_object, 'Import')
            return False


        # read configuration
        self._set_source_config(harvest_object.source.config)

        # prepare context
        context = {
            'model': model,
            'session': model.Session,
            'user': self._get_user_name(),
            # Tunnelled to pass to spatial_plugin
            'config': dict(self.source_config)
        }

        # Flag previous object as not current anymore
        # Get the last harvested object (if any)
        previous_object = model.Session.query(HarvestObject) \
                            .filter(HarvestObject.guid==harvest_object.guid) \
                            .filter(HarvestObject.current==True) \
                            .first()
                            
        if previous_object and not self.force_import:
            previous_object.current = False
            previous_object.add()

        ##############################################

        # evaluate the new status
        if self.force_import:
            status = 'change'
        else:
            status = self._get_object_extra(harvest_object, 'status')

        if status == 'delete':
            return self._delete(context, harvest_object)

        ###################
        # TODO guess the 'right' ISpatialHarvester
        
        # Validate ISO document
        is_valid, _status, _plugin, _validator = self._validate(harvest_object)
        if not is_valid:
            # If validation errors were found, import will stop unless
            # harvester validation flag says otherwise
            # TODO better policy, based on cumulated _status
            #  a boolean can't express too much,
            #  we should be able to ask
            if not self.source_config.get('continue_on_validation_errors') \
                    and \
                    not p.toolkit.asbool(config.get('ckanext.spatial.harvest.continue_on_validation_errors', False)):
                return False
        # Build the package dict    
        package_dict = None
        if not _plugin:
            # if not spatial_plugins:
            log.error('unable to guess the format using validator, '+\
                'fallback to default iso19139 implementation')

            csw_harvester = self._get_csw_harvester()
            
            # fallback to default parent implementation
                # TODO rise a ticket: unable to extend CSWHarvester
                # super.get_package_dict(iso_values, harvest_object)
                # overlaps but not implements ISpatialHarvester method
                # harvester.get_package_dict(context, {
                #     'package_dict': package_dict,
                #     'iso_values': parsed_values,
                #     'xml_tree': parsed_values.xml_tree,
                #     'harvest_object': harvest_object,
                # })

            if csw_harvester:
                # Parse ISO document
                try:
                    from ckanext.spatial.model import ISODocument
                    iso_parser = ISODocument(harvest_object.content)
                    parsed_values = iso_parser.read_values()
                except Exception as e:
                    self._save_object_error('Error parsing ISO document for object {0}: {1}'.format(harvest_object.id, six.text_type(e)),
                                            harvest_object, 'Import')
                    return False

                package_dict = csw_harvester.get_package_dict(parsed_values, harvest_object)
        else:
            # a plugin has been found and used to parse
            # let's use that implementation to provide a package

            # Parse ISO document
            # TODO use _status and policy to understand which parser to use
            # this may require an interface method from ISpatialHarvester
            try:
                parser = ISO19115Document(harvest_object.content)
                parsed_values = parser.read_values()
            except Exception as e:
                self._save_object_error('Error parsing ISO document for object {0}: {1}'.format(harvest_object.id, six.text_type(e)),
                                        harvest_object, 'Import')
                return False
            
            package_dict = _plugin.get_package_dict(context, {
                'package_dict': package_dict,
                'iso_values': parsed_values,
                # TODO ticket
                # should be passed by base parser.read_values()
                # but it's not there...
                'xml_tree': parsed_values.get('xml_tree',etree.fromstring(harvest_object.content)),
                'harvest_object': harvest_object,
            })

        if not package_dict:
            log.error('No package dict returned, aborting import for object {0}'.format(harvest_object.id))
            return False

        # Update GUID with the one on the document
        iso_guid = parsed_values.get('guid')
        self._set_guid(harvest_object, iso_guid)
        
        # Get document modified date
        metadata_date = parsed_values.get('metadata-date')
        if metadata_date:
            import dateutil
            try:
                harvest_object.metadata_modified_date = dateutil.parser.parse(metadata_date, ignoretz=True)
            except ValueError:
                self._save_object_error('Could not extract reference date for object {0} ({1})'
                            .format(harvest_object.id, parsed_values['metadata-date']), harvest_object, 'Import')
                return False
        else:
            import datetime
            #TODO log warn!
            harvest_object.metadata_modified_date = datetime.datetime.today()

        ###################

        # The default package schema does not like Upper case tags
        tag_schema = logic.schema.default_tags_schema()
        tag_schema['name'] = [not_empty, six.text_type]
        try:
            if status == 'new':

                # TODO doublecheck when to .add()
                # Flag this object as the current one
                harvest_object.current = True
                harvest_object.add()

                # create
                package_schema = logic.schema.default_create_package_schema()
                package_schema['tags'] = tag_schema
                context['schema'] = package_schema
                self._new(context, log, harvest_object, package_dict)

            else:

                # update or delete
                package_schema = logic.schema.default_update_package_schema()
                package_schema['tags'] = tag_schema
                context['schema'] = package_schema

                if status == 'change':

                    # TODO doublecheck when to .add()
                    # Flag this object as the current one
                    harvest_object.current = True
                    harvest_object.add()
                    
                    # TODO restore if deleted
                    if harvest_object.package and harvest_object.package.state=='deleted':
                        # undelete
                        package_dict['state']='active'

                        # update
                        self._change(context, log, harvest_object, package_dict)

                    # Check if the modified date is more recent
                    elif not self.force_import \
                            and previous_object and \
                            harvest_object.metadata_modified_date <= previous_object.metadata_modified_date:
                        log.info('Document with GUID %s unchanged, skipping...' % (harvest_object.guid))
                        # Assign the previous job id to the new object to
                        # avoid losing history
                        harvest_object.harvest_job_id = previous_object.job.id
                        harvest_object.add()
                        # Delete the previous object to avoid cluttering the object table
                        previous_object.delete()
                    else:
                        # update
                        self._change(context, log, harvest_object, package_dict)

                self._index(context, log, harvest_object, package_dict)
        except p.toolkit.ValidationError as e:
            self._save_object_error('Validation Error: %s' % six.text_type(e.error_summary), harvest_object, 'Import')
            return False 

        model.Session.commit()

        return True

    def _set_guid(self, harvest_object, iso_guid):
        import uuid
        import hashlib
        if iso_guid and harvest_object.guid != iso_guid:
            # First make sure there already aren't current objects
            # with the same guid
            existing_object = model.Session.query(HarvestObject.id) \
                            .filter(HarvestObject.guid==iso_guid) \
                            .filter(HarvestObject.current==True) \
                            .first()
            if existing_object:
                self._save_object_error('Object {0} already has this guid {1}'.format(existing_object.id, iso_guid),
                        harvest_object, 'Import')
                return False

            harvest_object.guid = iso_guid
            harvest_object.add()

        # Generate GUID if not present (i.e. it's a manual import)
        if not harvest_object.guid:
            m = hashlib.md5()
            m.update(harvest_object.content.encode('utf8', 'ignore'))
            harvest_object.guid = m.hexdigest()
            harvest_object.add() #????

    def _validate(self, harvest_object):
        '''
            :returns: [True|False] status plugin_name
            if True some validator has passed (first win)
             in that case also the plugin is passed
             (True, status[plugin_name]['errors'], plugin, validator)
            if False the plugin name is false and a report 
             can be located under:
             status[plugin_name]['errors']
        '''
        # Add any custom validators from extensions
        is_valid = False
        status = {}
        for plugin in p.PluginImplementations(ISpatialHarvester):
            
            # TODO priority / preferences / order (let's define harvester options to use into get_validators())?
            for validator in plugin.get_validators():
                # TODO this assume document as xml, we can do better... (using csw outputformat)
                _errors=[]
                try:
                    # TODO
                    # report:
                    #   File "/srv/app/src_extensions/ckanext-spatial/ckanext/spatial/harvesters/base.py", line 827, in _validate_document
                    #     valid, profile, errors = validator.is_valid(xml)
                    #     ValueError: need more than 2 values to unpack
                    # is_valid, _profile, _errors = self._validate_document(harvest_object.content, harvest_object, validator)
                    # is_valid interface is also specifying an different tuple:
                    # class XsdValidator(BaseValidator):
                    # '''Base class for validators that use an XSD schema.'''
                    # @classmethod
                    # def _is_valid(cls, xml, xsd_filepath, xsd_name):                
                    # Returns:
                    #   (is_valid, [(error_message_string, error_line_number)])
                    # which instead (as is currently used) should be:
                    #   (is_valid, [(error_line_number, error_message_string)])

                    # if csw outputformat application/xml
                    
                    document_string = re.sub('<\?xml(.*)\?>', '', harvest_object.content)
                    try:
                        _xml = etree.fromstring(document_string)
                    except etree.XMLSyntaxError as e:
                        self._save_object_error('Could not parse XML file: {0}'.format(six.text_type(e)), harvest_object, 'Import')
                        return False, None, []

                    is_valid, _errors = validator.is_valid(_xml)
                except Exception as e:
                    is_valid = False
                    _errors.insert(0, ('{0} Validation Error'.format(str(e)), e))

                plugin_name = plugin.name# or plugin.__class__.__name__

                # accumulate errors by (profile and plugin)
                status.update({plugin_name:{'status':is_valid, 'validator':validator.name, 'errors':_errors}})
                
                # The first win, order policy matter!
                if is_valid:
                    return is_valid, status, plugin, validator
                    
                # continue iterating to guess the right profile

        return is_valid, status, None, None

    def _delete(self, log, context, harvest_object):
        # Delete package
        context.update({
            'ignore_auth': True,
        })
        p.toolkit.get_action('package_delete')(context, {'id': harvest_object.package_id})
        log.info('Deleted package {0} with guid {1}'.format(harvest_object.package_id, harvest_object.guid))
        return True

    def _change(self, context, log, harvest_object, package_dict):
        package_dict['id'] = harvest_object.package_id
        try:
            package_id = p.toolkit.get_action('package_update')(context, package_dict)
            log.info('Updated package %s with guid %s', package_id, harvest_object.guid)
        except p.toolkit.ValidationError as e:
            self._save_object_error('Validation Error: %s' % six.text_type(e.error_summary), harvest_object, 'Import')
            return False

    def _index(self, context, log, harvest_object, package_dict):

        # Reindex the corresponding package to update the reference to the
        # harvest object
        if ((config.get('ckanext.spatial.harvest.reindex_unchanged', True) != 'False'
            or self.source_config.get('reindex_unchanged') != 'False')
            and harvest_object.package_id):
            context.update({'validate': False, 'ignore_auth': True})
            try:
                package_dict = logic.get_action('package_show')(context,
                    {'id': harvest_object.package_id})
            except p.toolkit.ObjectNotFound:
                # TODO LOG?!?!
                pass
            else:
                for extra in package_dict.get('extras', []):
                    if extra['key'] == 'harvest_object_id':
                        extra['value'] = harvest_object.id
                if package_dict:
                    from ckan.lib.search.index import PackageSearchIndex
                    PackageSearchIndex().index_package(package_dict)
        
    def _new(self, context, log, harvest_object, package_dict):
        package_schema = context['schema']
        # We need to explicitly provide a package ID, otherwise ckanext-spatial
        # won't be be able to link the extent to the package.
        import uuid
        package_dict['id'] = six.text_type(uuid.uuid4())
        package_schema['id'] = [six.text_type]

        # Save reference to the package on the object
        harvest_object.package_id = package_dict['id']
        harvest_object.add()
        # Defer constraints and flush so the dataset can be indexed with
        # the harvest object id (on the after_show hook from the harvester
        # plugin)
        model.Session.execute('SET CONSTRAINTS harvest_object_package_id_fkey DEFERRED')
        model.Session.flush()
        
        package_id = p.toolkit.get_action('package_create')(context, package_dict)
        log.info('Created new package %s with guid %s', package_id, harvest_object.guid)
    
#####################################################
# TOOLS
#####################################################

def elem2dict(node):
    """
    Convert an lxml.etree node tree into a dict.
    """
    result = {}

    for element in node.iterchildren():
        # Remove namespace prefix
        key = element.tag.split('}')[1] if '}' in element.tag else element.tag

        # Process element as tree element if the inner XML contains non-whitespace content
        if element.text and element.text.strip():
            value = element.text
        else:
            value = elem2dict(element)
        if key in result:

            
            if type(result[key]) is list:
                result[key].append(value)
            else:
                tempvalue = result[key].copy()
                result[key] = [tempvalue, value]
        else:
            result[key] = value
    return result